{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.089571Z",
     "start_time": "2025-09-06T17:09:39.771833Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyroomacoustics as pra\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import os\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics.audio import SpeechReverberationModulationEnergyRatio, ShortTimeObjectiveIntelligibility\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from src.dataset import SignalDataset, TRUNetDataset\n",
    "from src.loss import loss_tot, loss_MR, loss_MR_w\n",
    "from NISQA_s.src.core.model_torch import model_init\n",
    "from NISQA_s.src.utils.process_utils import process\n",
    "from models.fspen import FullSubPathExtension\n",
    "\n",
    "import librosa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89eb691c7b756838",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.094127Z",
     "start_time": "2025-09-06T17:09:42.090693Z"
    }
   },
   "outputs": [],
   "source": [
    "# # DATA_DIR = os.path.join(\"..\", \"data\", \"musan\", \"speech\")\n",
    "# DATA_DIR = os.path.join(\"..\", \"data\", \"DS_10283_2791\")\n",
    "# TRAIN_DIR = os.path.join(DATA_DIR, \"clean_trainset_56spk_wav\")\n",
    "# \n",
    "# TEST_DIR = os.path.join(DATA_DIR, \"clean_testset_wav\")\n",
    "# # TRAIN_DIR = os.path.join(DATA_DIR, \"train_chunks\")\n",
    "# # TEST_DIR = os.path.join(DATA_DIR, \"test_chunks\")\n",
    "# RIR_DIR = os.path.join(\"..\", \"data\", \"RIRs\")\n",
    "# # RIR_DIR = os.path.join(\"..\", \"data\", \"rirs_noises\", \"RIRS_NOISES\", \"real_rirs\")\n",
    "# # NOISE_DIR = os.path.join(\"..\", \"data\", \"test-noise\", \"noise\", \"white\")\n",
    "# NOISE_DIR = os.path.join(\"..\", \"data\", \"rirs_noises\", \"RIRS_NOISES\", \"real_rirs_isotropic_noises\")\n",
    "# CHKP_DIR = os.path.join(\"..\", \"checkpoints\")\n",
    "# NISQA_PATH = \"../NISQA_s/config/nisqa_s.yaml\"\n",
    "# np.set_printoptions(precision=3)\n",
    "# torch.set_printoptions(precision=3)\n",
    "DATA_DIR = os.path.join(\"data\", \"wav48\")\n",
    "# TRAIN_DIR = os.path.join(DATA_DIR, \"clean_trainset_56spk_wav\")\n",
    "\n",
    "# TEST_DIR = os.path.join(DATA_DIR, \"clean_testset_wav\")\n",
    "# TRAIN_DIR = os.path.join(DATA_DIR, \"train_chunks\")\n",
    "# TEST_DIR = os.path.join(DATA_DIR, \"test_chunks\")\n",
    "RIR_DIR = os.path.join(\"data\", \"rirs48\")\n",
    "# RIR_DIR = os.path.join(\"..\", \"data\", \"rirs_noises\", \"RIRS_NOISES\", \"real_rirs\")\n",
    "# NOISE_DIR = os.path.join(\"..\", \"data\", \"test-noise\", \"noise\", \"white\")\n",
    "NOISE_DIR = os.path.join(\"data\", \"noise48\")\n",
    "CHKP_DIR = \"checkpoints\"\n",
    "NISQA_PATH = \"NISQA_s/config/nisqa_s.yaml\"\n",
    "np.set_printoptions(precision=3)\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba5af93282e86a66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.114044Z",
     "start_time": "2025-09-06T17:09:42.095196Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x792a7850f9b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1984\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb2df54b402e9805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.261158Z",
     "start_time": "2025-09-06T17:09:42.116029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's cuda time!!!\n"
     ]
    }
   ],
   "source": [
    "N_FFTS = 512\n",
    "HOP_LENGTH = 256 # int(0.01625 * 16_000) # 256\n",
    "# N_FFTS = 1024\n",
    "# HOP_LENGTH = 512\n",
    "SR = 48_000\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"It's {DEVICE} time!!!\")\n",
    "N_DEVICES = max(torch.cuda.device_count(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60b6875b7300917c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.355003Z",
     "start_time": "2025-09-06T17:09:42.262688Z"
    }
   },
   "outputs": [],
   "source": [
    "PCS = torch.ones(257, device=DEVICE)      # Perceptual Contrast Stretching\n",
    "PCS[0:3] = 1\n",
    "PCS[3:6] = 1.070175439\n",
    "PCS[6:9] = 1.182456140\n",
    "PCS[9:12] = 1.287719298\n",
    "PCS[12:138] = 1.4       # Pre Set\n",
    "PCS[138:166] = 1.322807018\n",
    "PCS[166:200] = 1.238596491\n",
    "PCS[200:241] = 1.161403509\n",
    "PCS[241:256] = 1.077192982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db6f971821905ad7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.365788Z",
     "start_time": "2025-09-06T17:09:42.355833Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(NISQA_PATH, 'r') as stream:\n",
    "    nisqa_args = yaml.safe_load(stream)\n",
    "nisqa_args[\"ms_n_fft\"] = N_FFTS\n",
    "nisqa_args[\"hop_length\"] = HOP_LENGTH\n",
    "nisqa_args[\"ms_win_length\"] = N_FFTS\n",
    "nisqa_args[\"ckp\"] = nisqa_args[\"ckp\"][3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3641d2ccf7f3550d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.395340Z",
     "start_time": "2025-09-06T17:09:42.366778Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakhar/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "nisqa, h0_nisqa, c0_nisqa = model_init(nisqa_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "882580e76f67e0db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.401754Z",
     "start_time": "2025-09-06T17:09:42.396912Z"
    }
   },
   "outputs": [],
   "source": [
    "srmr = SpeechReverberationModulationEnergyRatio(fs=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0dcf8be0826e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.412879Z",
     "start_time": "2025-09-06T17:09:42.402611Z"
    }
   },
   "outputs": [],
   "source": [
    "stoi = ShortTimeObjectiveIntelligibility(SR, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "800220d5c2d4fe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.423705Z",
     "start_time": "2025-09-06T17:09:42.413817Z"
    }
   },
   "outputs": [],
   "source": [
    "# pesq = PerceptualEvaluationSpeechQuality(SR, 'nb') # fs should be 16_000 or less\n",
    "# pesq = PesqLoss(1.0,\n",
    "#     sample_rate=SR,\n",
    "#     n_fft=N_FFTS,\n",
    "#     win_length=N_FFTS,\n",
    "#     hop_length=HOP_LENGTH,\n",
    "# ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6117433689b257c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.496480Z",
     "start_time": "2025-09-06T17:09:42.425598Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_dataset = TRUNetDataset(TRAIN_DIR, sr=16_000, noise_dir=NOISE_DIR, rir_dir=RIR_DIR, snr=(0, 20), return_noise=False, return_rir=False)\n",
    "# test_dataset = TRUNetDataset(TEST_DIR, sr=16_000, noise_dir=NOISE_DIR, snr=(0, 20), rir_dir=RIR_DIR, return_noise=False, return_rir=False)\n",
    "\n",
    "dataset = TRUNetDataset(DATA_DIR, sr=SR, noise_dir=NOISE_DIR, rir_dir=RIR_DIR, snr=[-5, 0, 5, 10], rir_proba=0.7, noise_proba=0.7, return_noise=False, return_rir=False)\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b992202b1db8b443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.501543Z",
     "start_time": "2025-09-06T17:09:42.497889Z"
    }
   },
   "outputs": [],
   "source": [
    "def vorbis_window(winlen, device=\"cuda\"):\n",
    "    sq = torch.sin(torch.pi/2*(torch.sin(torch.pi/winlen*(torch.arange(winlen)-0.5))**2)).float()\n",
    "    return sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "989c1103a22ceec9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.512249Z",
     "start_time": "2025-09-06T17:09:42.502847Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    if not batch:\n",
    "        return torch.zeros(0), torch.zeros(0)\n",
    "\n",
    "    input_signal, target_signal, noise, rir = zip(*batch)\n",
    "        \n",
    "    max_len_s = max(s.shape[-1] for s in input_signal)\n",
    "    \n",
    "    padded_input = torch.zeros(len(input_signal), max_len_s)\n",
    "    padded_target = torch.zeros(len(target_signal), max_len_s)\n",
    "    \n",
    "    for i, s in enumerate(input_signal):\n",
    "        padded_input[i, :s.shape[-1]] = s\n",
    "        padded_target[i, :s.shape[-1]] = target_signal[i]\n",
    "\n",
    "    return padded_input, padded_target\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    padded_input, padded_target = pad_sequence(batch)\n",
    "    \n",
    "    # padded_input = padded_input.unfold(-1, 16_000 * 2, 16_000)\n",
    "    # padded_target = padded_target.unfold(-1, 16_000 * 2, 16_000)\n",
    "    \n",
    "    window = vorbis_window(N_FFTS)\n",
    "    \n",
    "    padded_input = padded_input.reshape(-1, padded_input.shape[-1])\n",
    "    input_spec = torch.stft(\n",
    "            padded_input,\n",
    "            n_fft=N_FFTS,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            # onesided=True,\n",
    "            win_length=N_FFTS,\n",
    "            window=window,\n",
    "            return_complex=True,\n",
    "            normalized=True,\n",
    "            center=True\n",
    "        ) \n",
    "    to_gt_spec = padded_input.reshape(-1, padded_target.shape[-1])\n",
    "    gt_spec = torch.stft(\n",
    "            to_gt_spec,\n",
    "            n_fft=N_FFTS,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            # onesided=True,\n",
    "            win_length=N_FFTS,\n",
    "            window=window,\n",
    "            return_complex=True,\n",
    "            normalized=True,\n",
    "            center=True\n",
    "        ) \n",
    "    \n",
    "    padded_target = padded_target.reshape(-1, padded_target.shape[-1])\n",
    "\n",
    "    return input_spec, padded_target, gt_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "532a90dc5396aa49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.528263Z",
     "start_time": "2025-09-06T17:09:42.513109Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE * N_DEVICES, shuffle=True, drop_last=True, collate_fn=collate_fn, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE * N_DEVICES, shuffle=False, drop_last=False, collate_fn=collate_fn, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14301d88721eb6d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.543081Z",
     "start_time": "2025-09-06T17:09:42.529314Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, with_noise=True, with_rir=True, device=\"cuda\", epoch=0, draw_every=1):\n",
    "    total_train_loss = 0\n",
    "    # MOS NOI DISC COL LOUD\n",
    "    total_train_nisqa = torch.zeros(5)\n",
    "    total_train_srmr = 0\n",
    "    total_train_stoi = 0\n",
    "    # ind = 0\n",
    "    out = None\n",
    "    noisy_in = None\n",
    "    model.train()\n",
    "    for input_spec, gt_signal, gt_spec in tqdm(train_loader, desc=\"Train model \"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_spec = input_spec.to(device, non_blocking=True)\n",
    "        gt_signal = gt_signal.to(device, non_blocking=True)\n",
    "\n",
    "        # input_spec_ = input_spec\n",
    "        # abs_spectrum = input_spec.abs()\n",
    "        # input_spec = torch.permute(torch.view_as_real(input_spec), dims=(0, 2, 3, 1))\n",
    "        # batch, frames, channels, frequency = input_spec.shape\n",
    "        # \n",
    "        # abs_spectrum = torch.permute(abs_spectrum, dims=(0, 2, 1))\n",
    "        # abs_spectrum = torch.reshape(abs_spectrum, shape=(batch, frames, 1, frequency))\n",
    "        # h0 = torch.randn(1, batch * 16, 16 // 8, device=device)\n",
    "        # h0 = [[torch.randn(1, batch * 32, 16 // 8, device=device) for _ in range(8)]\n",
    "        #               for _ in range(3)]\n",
    "        # print(PCS.shape, torch.transpose(torch.log1p(torch.abs(input_spec)), 1, 0).shape)\n",
    "        # print(input_spec.dtype)\n",
    "        h0 = [[torch.zeros(1, BATCH_SIZE * 32, 16 // 8, device=input_spec.device) for _ in range(8)] for _ in range(2)]\n",
    "\n",
    "        input_spec_pcs = PCS[:, None, None] * torch.transpose(torch.log1p(torch.abs(input_spec)), 1, 0)\n",
    "        input_spec_pcs = torch.transpose(input_spec_pcs, 1, 0)\n",
    "        input_spec_pcs = torch.polar(input_spec_pcs, input_spec.angle())\n",
    "        abs_spectrum_pcs = input_spec_pcs.abs()\n",
    "        # print(torch.transpose(torch.log1p(torch.abs(input_spec)), 1, 0).dtype)\n",
    "        input_spec_pcs = torch.permute(torch.view_as_real(input_spec_pcs), dims=(0, 2, 3, 1))\n",
    "        batch, frames, channels, frequency = input_spec_pcs.shape\n",
    "\n",
    "        abs_spectrum_pcs = torch.permute(abs_spectrum_pcs, dims=(0, 2, 1))\n",
    "        abs_spectrum_pcs = torch.reshape(abs_spectrum_pcs, shape=(batch, frames, 1, frequency))\n",
    "        \n",
    "        # print(input_spec_pcs.shape, abs_spectrum_pcs.shape)\n",
    "        output, _ = model(input_spec_pcs, abs_spectrum_pcs, h0)\n",
    "        # print(output.shape)\n",
    "        output = torch.permute(output, dims=(0, 3, 1, 2))\n",
    "        output[..., 0] = torch.expm1(output[..., 0])\n",
    "        output = torch.view_as_complex(output)\n",
    "        # output_d, output_n, output_r, _, _ = model(input_spec, h_f, h_t)\n",
    "\n",
    "        # output_d = torch.polar(torch.abs(output_d), input_spec.angle())\n",
    "\n",
    "        window = vorbis_window(N_FFTS).to(device)\n",
    "        # print(output_d.shape, input_spec.shape)\n",
    "        out_wave = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                               window=window,\n",
    "                               # onesided=True,\n",
    "                               return_complex=False,\n",
    "                               normalized=True,\n",
    "                               center=True)#, length=gt_signal.shape[-1])\n",
    "        min_l = min(out_wave.shape[-1], gt_signal.shape[-1])\n",
    "        loss_mr = loss_MR(out_wave[..., :min_l], gt_signal[..., :min_l], nffts=[128, 256, 512, 1024, 2048, 4096])\n",
    "        # loss_mr_w = loss_MR_w(out_wave, gt_signal)\n",
    "        \n",
    "        loss = loss_mr # + loss_mr_w\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(out_wave.shape)\n",
    "        nisqa_score, _, _ = process(out_wave.detach().cpu(), SR, nisqa, h0_nisqa, c0_nisqa, nisqa_args)\n",
    "        # srmr_score = srmr(out_wave)\n",
    "        # stoi_score = stoi(out_wave[..., :min_l], gt_signal[..., :min_l])\n",
    "        \n",
    "        total_train_nisqa += nisqa_score[0]\n",
    "        # total_train_srmr += srmr_score.mean(axis=-1)\n",
    "        # total_train_stoi += stoi_score.mean(axis=-1)\n",
    "        \n",
    "        total_train_loss += loss.detach().item()  \n",
    "\n",
    "        assert loss.detach().isnan().any().item() is False, \"Train loss is NaN\"\n",
    "        \n",
    "    return (model, optimizer, total_train_loss / len(train_loader), total_train_nisqa / len(train_loader), \n",
    "            total_train_srmr / len(train_loader), total_train_stoi / len(train_loader))\n",
    "            \n",
    "def evaluate(model, test_loader, with_noise=True, with_rir=True, device=\"cuda\", epoch=0):\n",
    "    total_test_loss = 0\n",
    "    total_test_nisqa = torch.zeros(5)\n",
    "    total_test_srmr = 0\n",
    "    total_test_stoi = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for input_spec, gt_signal, gt_spec in tqdm(test_loader, desc=\"Test model \"):\n",
    "            input_spec = input_spec.to(device, non_blocking=True)\n",
    "            gt_signal = gt_signal.to(device, non_blocking=True)\n",
    "            \n",
    "            # abs_spectrum = input_spec.abs()\n",
    "            # input_spec = torch.permute(torch.view_as_real(input_spec), dims=(0, 2, 3, 1))\n",
    "            # batch, frames, channels, frequency = input_spec.shape\n",
    "            # abs_spectrum = torch.permute(abs_spectrum, dims=(0, 2, 1))\n",
    "            # abs_spectrum = torch.reshape(abs_spectrum, shape=(batch, frames, 1, frequency))\n",
    "            h0 = [[torch.zeros(1, BATCH_SIZE * 32, 16 // 8, device=input_spec.device) for _ in range(8)] for _ in range(2)]\n",
    "\n",
    "            input_spec_pcs = PCS[:, None, None] * torch.transpose(torch.log1p(torch.abs(input_spec)), 1, 0)\n",
    "            input_spec_pcs = torch.transpose(input_spec_pcs, 1, 0)\n",
    "            input_spec_pcs = torch.polar(input_spec_pcs, input_spec.angle())\n",
    "            abs_spectrum_pcs = input_spec_pcs.abs()\n",
    "            # print(torch.transpose(torch.log1p(torch.abs(input_spec)), 1, 0).dtype)\n",
    "            input_spec_pcs = torch.permute(torch.view_as_real(input_spec_pcs), dims=(0, 2, 3, 1))\n",
    "            batch, frames, channels, frequency = input_spec_pcs.shape\n",
    "    \n",
    "            abs_spectrum_pcs = torch.permute(abs_spectrum_pcs, dims=(0, 2, 1))\n",
    "            abs_spectrum_pcs = torch.reshape(abs_spectrum_pcs, shape=(batch, frames, 1, frequency))\n",
    "            \n",
    "            output, _ = model(input_spec_pcs, abs_spectrum_pcs, h0)\n",
    "            \n",
    "            output = torch.permute(output, dims=(0, 3, 1, 2))\n",
    "            output = torch.view_as_complex(output)\n",
    "    \n",
    "            # output_d, output_n, output_r, _, _ = model(input_spec, h_f, h_t)\n",
    "            # output_d = torch.polar(torch.abs(output_d), input_spec.angle())\n",
    "\n",
    "            window = vorbis_window(N_FFTS).to(device)\n",
    "            out_wave = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                                   window=window,\n",
    "                                   return_complex=False,\n",
    "                                   normalized=True,\n",
    "                                   center=True)\n",
    "            # out_wave, _ = SignalDataset.normalize_audio(out_wave)\n",
    "            # out_wave = 2 * (out_wave - out_wave.min()) / (out_wave.max() - out_wave.min() + 1e-8) - 1\n",
    "            min_l = min(out_wave.shape[-1], gt_signal.shape[-1])\n",
    "            loss_mr = loss_MR(out_wave[..., :min_l], gt_signal[..., :min_l], nffts=[128, 256, 512, 1024, 2048, 4096])\n",
    "            # loss_mr_w = loss_MR_w(out_wave, gt_signal) # + loss_MR_w(out_noise, noise) + loss_MR_w(out_rir, rir)\n",
    "            \n",
    "            loss = loss_mr # + loss_mr_w # + mask_loss_abs + mask_loss_angle\n",
    "\n",
    "            total_test_loss += loss.detach().item()\n",
    "            nisqa_score, _, _ = process(out_wave.detach().cpu(), SR, nisqa, h0_nisqa, c0_nisqa, nisqa_args)\n",
    "            # srmr_score = srmr(out_wave)\n",
    "            # stoi_score = stoi(out_wave[..., :min_l], gt_signal[..., :min_l])\n",
    "            \n",
    "            total_test_nisqa += nisqa_score[0]\n",
    "            # total_test_srmr += srmr_score.mean(axis=-1)\n",
    "            # total_test_stoi += stoi_score.mean(axis=-1)\n",
    "            assert loss.detach().isnan().any().item() is False, \"Val loss is NaN\"\n",
    "     \n",
    "    return (total_test_loss / len(test_loader), total_test_nisqa / len(test_loader),\n",
    "            total_test_srmr / len(test_loader), total_test_stoi / len(test_loader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "86d848ca2a56efcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:42.561704Z",
     "start_time": "2025-09-06T17:09:42.544361Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def get_model_name(chkp_folder, model_name=None):\n",
    "    # Выбираем имя чекпоинта для сохранения\n",
    "    if model_name is None:\n",
    "        if os.path.exists(chkp_folder):\n",
    "            num_starts = len(os.listdir(chkp_folder)) + 1\n",
    "        else:\n",
    "            num_starts = 1\n",
    "        model_name = f'model#{num_starts}'\n",
    "    else:\n",
    "        if \"#\" not in model_name:\n",
    "            model_name += \"#0\"\n",
    "    changed = False\n",
    "    while os.path.exists(os.path.join(chkp_folder, model_name + '.pt')):\n",
    "        model_name, ind = model_name.split(\"#\")\n",
    "        model_name += f\"#{int(ind) + 1}\"\n",
    "        changed=True\n",
    "    if changed:\n",
    "        warnings.warn(f\"Selected model_name was used already! To avoid possible overwrite - model_name changed to {model_name}\")\n",
    "    return model_name\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def learning_loop(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    scheduler=None,\n",
    "    min_lr=None,\n",
    "    epochs=10,\n",
    "    val_every=1,\n",
    "    draw_every=1,\n",
    "    with_noise=True,\n",
    "    with_rir=True,\n",
    "    model_name=None,\n",
    "    chkp_folder=\"../checkpoints/fspen_chkp\",\n",
    "    plots=None,\n",
    "    starting_epoch=0,\n",
    "    device=\"cuda\",\n",
    "):\n",
    "    model_name = get_model_name(chkp_folder, model_name)\n",
    "    \n",
    "    if plots is None:\n",
    "        plots = {\n",
    "            'train loss': [],\n",
    "            'train NISQA': [],\n",
    "            'train SRMR': [],\n",
    "            'train STOI': [],\n",
    "            'val loss': [],\n",
    "            'val NISQA': [],\n",
    "            'val SRMR': [],\n",
    "            'val STOI': [],\n",
    "            \"learning rate\": [],\n",
    "        }\n",
    "\n",
    "    max_mos = 0\n",
    "\n",
    "    for epoch in np.arange(1, epochs+1) + starting_epoch:\n",
    "        print(f'#{epoch}/{epochs}:')\n",
    "\n",
    "        plots['learning rate'].append(get_lr(optimizer))\n",
    "        \n",
    "        (model, optimizer, train_loss, train_nisqa, train_srmr, train_stoi) = train(model, train_loader, optimizer, with_noise=with_noise, with_rir=with_rir, device=device, epoch=epoch, draw_every=draw_every)\n",
    "        # print(train_nisqa)\n",
    "        plots['train loss'].append(train_loss)\n",
    "        plots['train NISQA'].append(train_nisqa[None, :].cpu())\n",
    "        plots['train SRMR'].append(train_srmr)\n",
    "        plots['train STOI'].append(train_stoi)\n",
    "\n",
    "        if not (epoch % val_every):\n",
    "            # print(\"validate\")\n",
    "            (val_loss, val_nisqa, val_srmr, val_stoi) = evaluate(model, val_loader, with_noise=with_noise, with_rir=with_rir, device=device)\n",
    "            plots['val loss'].append(val_loss)\n",
    "            plots['val NISQA'].append(val_nisqa[None, :].cpu())\n",
    "            plots['val SRMR'].append(val_srmr)\n",
    "            plots['val STOI'].append(train_stoi)\n",
    "            \n",
    "            # Сохраняем модель\n",
    "            if not os.path.exists(chkp_folder):\n",
    "                os.makedirs(chkp_folder)\n",
    "            \n",
    "            # if max_mos <= val_nisqa[0]:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'plots': plots,\n",
    "                },\n",
    "                os.path.join(chkp_folder, model_name + '.pt'),\n",
    "            )\n",
    "            max_mos = val_nisqa[0]\n",
    "            \n",
    "            # Шедулинг\n",
    "            if scheduler:\n",
    "                try:\n",
    "                    scheduler.step()\n",
    "                except:\n",
    "                    scheduler.step(metrics=val_loss)\n",
    "\n",
    "        if not (epoch % draw_every):\n",
    "            clear_output(True)\n",
    "\n",
    "            hh = 4\n",
    "            ww = 2\n",
    "            plt_ind = 1\n",
    "            fig, ax = plt.subplots(hh, ww, figsize=(25, 12))\n",
    "            fig.suptitle(f'#{epoch}/{epochs}:')\n",
    "\n",
    "\n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('Learning rate')\n",
    "            plt.plot(plots[\"learning rate\"], 'b.-', label='lr', alpha=0.7)\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "\n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('Loss')\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['train loss'], 'r.-', label='train', alpha=0.7)\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['val loss'], 'g.-', label='val', alpha=0.7)\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "            \n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('SRMR')\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['train SRMR'], 'r.-', label='train', alpha=0.7)\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['val SRMR'], 'g.-', label='val', alpha=0.7)\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "            \n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('STOI')\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['train STOI'], 'r.-', label='train', alpha=0.7)\n",
    "            plt.plot(np.arange(1, epoch + 1), plots['val STOI'], 'g.-', label='val', alpha=0.7)\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "\n",
    "            nisqa_plot = torch.cat(plots['train NISQA'])\n",
    "            # if len(nisqa_plot.shape) == 1:\n",
    "            #     nisqa_plot = nisqa_plot[None, :]\n",
    "            # print(nisqa_plot.shape)\n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('Train NISQA')\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 0], '.-', label='MOS', alpha=0.7, markersize=20, color=\"blue\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 1], '.-', label='NOI', alpha=0.7, markersize=20, color=\"red\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 2], '.-', label='DISC', alpha=0.7, markersize=20, color=\"green\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 3], '.-', label='COL', alpha=0.7, markersize=20, color=\"yellow\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 4], '.-', label='LOUD', alpha=0.7, markersize=20, color=\"pink\")\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "\n",
    "            nisqa_plot = torch.cat(plots['val NISQA'], dim=0)\n",
    "            # if len(nisqa_plot.shape) == 1:\n",
    "            #     nisqa_plot = nisqa_plot[None, :]\n",
    "            plt.subplot(hh, ww, plt_ind)\n",
    "            plt.title('Val NISQA')\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 0], '.-', label='MOS', alpha=0.7, markersize=20, color=\"blue\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 1], '.-', label='NOI', alpha=0.7, markersize=20, color=\"red\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 2], '.-', label='DISC', alpha=0.7, markersize=20, color=\"green\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 3], '.-', label='COL', alpha=0.7, markersize=20, color=\"yellow\")\n",
    "            plt.plot(np.arange(1, epoch + 1), nisqa_plot[:, 4], '.-', label='LOUD', alpha=0.7, markersize=20, color=\"pink\")\n",
    "            plt.grid()\n",
    "            plt.legend()\n",
    "            plt_ind += 1\n",
    "\n",
    "            plt.show()\n",
    "            display(fig)\n",
    "                        \n",
    "        if min_lr and get_lr(optimizer) <= min_lr:\n",
    "            print(f'Learning process ended with early stop after epoch {epoch}')\n",
    "            break\n",
    "\n",
    "    \n",
    "    return model, optimizer, plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85e3cc1ef2621bc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:43.023102Z",
     "start_time": "2025-09-06T17:09:42.562805Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 2\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam, AdamW\n",
    "from src.fspen_configs import TrainConfig, TrainConfigLarge, TrainConfigLarge1\n",
    "configs = TrainConfigLarge()\n",
    "print(sum(configs.bands_num_in_groups), configs.dual_path_extension[\"num_modules\"])\n",
    "fspen = FullSubPathExtension(configs=configs).to(DEVICE) # TRUNet(nfft=N_FFTS, hop=HOP_LENGTH).cuda()\n",
    "\n",
    "optimizer = Adam(fspen.parameters(), lr=5e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 8, gamma=0.8, last_epoch=-1)\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, cooldown=1, patience=3, threshold=0.1, mode=\"min\", threshold_mode=\"abs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6b96c26f61a4fbd7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:43.031246Z",
     "start_time": "2025-09-06T17:09:43.024509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mfull_band_encoder.full_band_encoder.0.conv.weight ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.0.conv.bias ~  4         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.0.norm.weight ~  4         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.0.norm.bias ~  4         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.1.conv.weight ~  512       params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.1.conv.bias ~  16        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.1.norm.weight ~  16        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.1.norm.bias ~  16        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.2.conv.weight ~  6.144     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.2.conv.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.2.norm.weight ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.full_band_encoder.2.norm.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.global_features.weight   ~  4.096     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_encoder.global_features.bias     ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.0.conv.weight ~  256       params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.0.conv.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.1.conv.weight ~  448       params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.1.conv.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.2.conv.weight ~  704       params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.2.conv.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.3.conv.weight ~  1.280     params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.3.conv.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.4.conv.weight ~  1.920     params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_encoder.sub_band_encoders.4.conv.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_merge_layer.0.weight               ~  2.048     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_merge_layer.0.bias                 ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_merge_layer.2.weight               ~  2.048     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_merge_layer.2.bias                 ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.weight_ih_l0 ~  1.536     params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.weight_hh_l0 ~  768       params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.bias_ih_l0 ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.bias_hh_l0 ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.weight_ih_l0_reverse ~  1.536     params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.weight_hh_l0_reverse ~  768       params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.bias_ih_l0_reverse ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_rnn.bias_hh_l0_reverse ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_fc.weight ~  1.024     params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_fc.bias ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_norm.weight ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.intra_chunk_norm.bias ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.0.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.0.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.0.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.0.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.1.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.1.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.1.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.1.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.2.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.2.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.2.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.2.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.3.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.3.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.3.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.3.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.4.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.4.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.4.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.4.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.5.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.5.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.5.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.5.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.6.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.6.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.6.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.6.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.7.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.7.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.7.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_rnn.rnn_list.7.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_fc.weight ~  512       params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.0.inter_chunk_fc.bias ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.weight_ih_l0 ~  1.536     params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.weight_hh_l0 ~  768       params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.bias_ih_l0 ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.bias_hh_l0 ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.weight_ih_l0_reverse ~  1.536     params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.weight_hh_l0_reverse ~  768       params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.bias_ih_l0_reverse ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_rnn.bias_hh_l0_reverse ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_fc.weight ~  1.024     params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_fc.bias ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_norm.weight ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.intra_chunk_norm.bias ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.0.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.0.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.0.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.0.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.1.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.1.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.1.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.1.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.2.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.2.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.2.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.2.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.3.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.3.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.3.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.3.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.4.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.4.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.4.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.4.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.5.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.5.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.5.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.5.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.6.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.6.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.6.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.6.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.7.weight_ih_l0 ~  24        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.7.weight_hh_l0 ~  12        params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.7.bias_ih_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_rnn.rnn_list.7.bias_hh_l0 ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_fc.weight ~  512       params ~ grad: True\u001b[0m\n",
      "\u001b[32mdual_path_extension_rnn_list.1.inter_chunk_fc.bias ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_split_layer.0.weight               ~  2.048     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_split_layer.0.bias                 ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_split_layer.1.weight               ~  2.048     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfeature_split_layer.1.bias                 ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.0.conv.weight ~  8.192     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.0.conv.bias ~  64        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.0.convT.weight ~  6.144     params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.0.convT.bias ~  16        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.0.norm.weight ~  16        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.0.norm.bias ~  16        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.1.conv.weight ~  512       params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.1.conv.bias ~  16        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.1.convT.weight ~  512       params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.1.convT.bias ~  4         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.1.norm.weight ~  4         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.1.norm.bias ~  4         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.2.conv.weight ~  32        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.2.conv.bias ~  4         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.2.convT.weight ~  48        params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.2.convT.bias ~  2         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.2.norm.weight ~  2         params ~ grad: True\u001b[0m\n",
      "\u001b[32mfull_band_decoder.full_band_decoders.2.norm.bias ~  2         params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.0.fc.weight ~  256       params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.0.fc.bias ~  2         params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.1.fc.weight ~  384       params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.1.fc.bias ~  3         params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.2.fc.weight ~  768       params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.2.fc.bias ~  6         params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.3.fc.weight ~  1.408     params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.3.fc.bias ~  11        params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.4.fc.weight ~  2.560     params ~ grad: True\u001b[0m\n",
      "\u001b[32msub_band_decoder.sub_band_decoders.4.fc.bias ~  20        params ~ grad: True\u001b[0m\n",
      "\n",
      "In total:\n",
      "  - 59.132 params\n",
      "  - 59.132 learnable params\n",
      "\n",
      " . full_band_encoder:\n",
      " .   - 11.116 params\n",
      " .   - 11.116 learnable params\n",
      "\n",
      " . sub_band_encoder:\n",
      " .   - 4.928 params\n",
      " .   - 4.928 learnable params\n",
      "\n",
      " . feature_merge_layer:\n",
      " .   - 4.160 params\n",
      " .   - 4.160 learnable params\n",
      "\n",
      " . dual_path_extension_rnn_list:\n",
      " .   - 13.696 params\n",
      " .   - 13.696 learnable params\n",
      "\n",
      " . feature_split_layer:\n",
      " .   - 4.224 params\n",
      " .   - 4.224 learnable params\n",
      "\n",
      " . full_band_decoder:\n",
      " .   - 15.590 params\n",
      " .   - 15.590 learnable params\n",
      "\n",
      " . sub_band_decoder:\n",
      " .   - 5.418 params\n",
      " .   - 5.418 learnable params\n"
     ]
    }
   ],
   "source": [
    "from src.utils import model_num_params\n",
    "\n",
    "_, _ = model_num_params(fspen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b04e1a57872a5364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-06T17:09:50.603352Z",
     "start_time": "2025-09-06T17:09:43.032560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1/20:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train model :   0%|          | 4/15485 [00:00<44:12,  5.84it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fspen, optimizer, plots \u001b[38;5;241m=\u001b[39m \u001b[43mlearning_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfspen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_rir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfspen_voicebank_subband_loss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[35], line 67\u001b[0m, in \u001b[0;36mlearning_loop\u001b[0;34m(model, optimizer, train_loader, val_loader, scheduler, min_lr, epochs, val_every, draw_every, with_noise, with_rir, model_name, chkp_folder, plots, starting_epoch, device)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m plots[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning rate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(get_lr(optimizer))\n\u001b[0;32m---> 67\u001b[0m (model, optimizer, train_loss, train_nisqa, train_srmr, train_stoi) \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_rir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdraw_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdraw_every\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# print(train_nisqa)\u001b[39;00m\n\u001b[1;32m     69\u001b[0m plots[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[34], line 66\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, with_noise, with_rir, device, epoch, draw_every)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# loss_mr_w = loss_MR_w(out_wave, gt_signal)\u001b[39;00m\n\u001b[1;32m     64\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_mr \u001b[38;5;66;03m# + loss_mr_w\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# print(out_wave.shape)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fspen, optimizer, plots = learning_loop(fspen, optimizer, train_dataloader, test_dataloader, scheduler, draw_every=1, epochs=20, min_lr=1e-8, with_noise=False, with_rir=False, model_name=\"fspen_voicebank_subband_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1dd980bdd962b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_d = torch.load(os.path.join(CHKP_DIR, \"fspen_chkp\", \"fspen_voicebank_subband_loss_large#2.pt\"), weights_only=False)\n",
    "# \n",
    "# fspen.load_state_dict(state_d[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(state_d[\"optimizer_state_dict\"])\n",
    "# scheduler.load_state_dict(state_d[\"scheduler_state_dict\"])\n",
    "# plots = state_d[\"plots\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887399a63b1c19ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fspen, optimizer, plots = learning_loop(fspen, optimizer, train_dataloader, test_dataloader, scheduler, draw_every=1, epochs=500, min_lr=1e-8, with_noise=False, with_rir=False, model_name=\"fspen_voicebank_reverb\", plots=plots, starting_epoch=state_d[\"epoch\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef74b06720f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ems_dereverb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
