{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fba469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyroomacoustics as pra\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import profiler\n",
    "import torchaudio\n",
    "from torchmetrics.audio import SpeechReverberationModulationEnergyRatio, ShortTimeObjectiveIntelligibility\n",
    "\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from src.dataset import SignalDataset, TRUNetDataset\n",
    "from src.loss import loss_tot, loss_MR, loss_MR_w\n",
    "from models.fspen import FullSubPathExtension \n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from src.utils import model_eval, model_eval_fspen2x_ver3\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb4024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(\"data\", \"wav48\")\n",
    "# TRAIN_DIR = os.path.join(DATA_DIR, \"clean_trainset_56spk_wav\")\n",
    "\n",
    "TEST_DIR = os.path.join(\"data\", \"DS_10283_2791\", \"clean_testset_wav\")\n",
    "TEST_NOISE_DIR = os.path.join(\"data\", \"DS_10283_2791\", \"noisy_testset_wav\")\n",
    "# RIR_DIR = os.path.join(\"data\", \"rirs48_medium_2\", )\n",
    "NOISE_DIR = os.path.join(\"data\", \"demand\")\n",
    "\n",
    "CHKP_DIR = \"checkpoints\"\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81be6b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x78c0218bd850>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 1984\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe560be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's cpu time!!!\n"
     ]
    }
   ],
   "source": [
    "N_FFTS = 1024\n",
    "HOP_LENGTH = 512\n",
    "SR = 48_000\n",
    "\n",
    "DEVICE = \"cpu\" # torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"It's {DEVICE} time!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1d67bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_dict = {1: os.path.join(\"data\", \"rirs48_soft_2\"), 2: os.path.join(\"data\", \"rirs48_medium_2\"), 3: os.path.join(\"data\", \"rirs48_hard_2\")}\n",
    "dataset = TRUNetDataset(TEST_DIR, sr=48_000, noise_dir=NOISE_DIR, rir_dir=rir_dict, snr=[0, 5, 10, 15], rir_proba=0.9, noise_proba=1.0, rir_target=False, return_noise=False, return_rir=False)\n",
    "dataset.set_epoch(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c5c4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 3\n"
     ]
    }
   ],
   "source": [
    "from src.fspen_configs import TrainConfig48kHzEnc2x_ver2\n",
    "\n",
    "configs = TrainConfig48kHzEnc2x_ver2()\n",
    "print(sum(configs.bands_num_in_groups), configs.dual_path_extension[\"num_modules\"])\n",
    "fspen = FullSubPathExtension(configs=configs)# .to(DEVICE)\n",
    "\n",
    "state_d = torch.load(os.path.join(CHKP_DIR, \"fspen_chkp\", \"TrainConfig48kHzEnc2x_ver2_hard#1.pt\"), map_location=\"cpu\",  weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb29d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fspen.load_state_dict(state_d[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "260d6130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vorbis_window(winlen, device=\"cuda\"):\n",
    "    sq = torch.sin(torch.pi/2*(torch.sin(torch.pi/winlen*(torch.arange(winlen)-0.5))**2)).float()\n",
    "    return sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad069976",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakhar/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "from NISQA_s.src.core.model_torch import model_init\n",
    "from NISQA_s.src.utils.process_utils import process\n",
    "\n",
    "NISQA_PATH = \"NISQA_s/config/nisqa_s.yaml\"\n",
    "\n",
    "with open(NISQA_PATH, 'r') as stream:\n",
    "    nisqa_args = yaml.safe_load(stream)\n",
    "nisqa_args[\"ms_n_fft\"] = 512\n",
    "nisqa_args[\"hop_length\"] = 256\n",
    "nisqa_args[\"ms_win_length\"] = 512\n",
    "nisqa_args[\"ckp\"] = nisqa_args[\"ckp\"][3:]\n",
    "\n",
    "nisqa, h0_nisqa, c0_nisqa = model_init(nisqa_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3788834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    if not batch:\n",
    "        return torch.zeros(0), torch.zeros(0)\n",
    "\n",
    "    input_signal, target_signal, noise, rir = zip(*batch)\n",
    "        \n",
    "    max_len_s = max(s.shape[-1] for s in input_signal)\n",
    "    \n",
    "    padded_input = torch.zeros(len(input_signal), max_len_s)\n",
    "    padded_target = torch.zeros(len(target_signal), max_len_s)\n",
    "    \n",
    "    for i, s in enumerate(input_signal):\n",
    "        padded_input[i, :s.shape[-1]] = s\n",
    "        padded_target[i, :s.shape[-1]] = target_signal[i]\n",
    "\n",
    "    return padded_input, padded_target\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \n",
    "    padded_input, padded_target = pad_sequence(batch)\n",
    "        \n",
    "    padded_input = padded_input.reshape(-1, padded_input.shape[-1])\n",
    "    padded_target = padded_target.reshape(-1, padded_input.shape[-1])\n",
    "\n",
    "    return padded_input, padded_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a71b8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(dataset, batch_size=1, shuffle=False, drop_last=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f72b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def check_stream_inference(model, loader, window_size = 1 * SR, device=\"cpu\"):\n",
    "    model.eval()\n",
    "\n",
    "    result_nisqa_full = []\n",
    "    result_rtf_full = []\n",
    "    result_nisqa_chunk = []\n",
    "    result_rtf_chunk = []\n",
    "    with torch.no_grad():\n",
    "        for signal, target in tqdm(loader):\n",
    "            signal = signal.to(device)\n",
    "            target = target.to(device)\n",
    "            window = vorbis_window(N_FFTS).to(device)\n",
    "    \n",
    "            start_time = time.time()\n",
    "            spec = torch.stft(\n",
    "                signal,\n",
    "                n_fft=N_FFTS,\n",
    "                hop_length=HOP_LENGTH,\n",
    "                # onesided=True,\n",
    "                win_length=N_FFTS,\n",
    "                window=window,\n",
    "                return_complex=True,\n",
    "                normalized=True,\n",
    "                center=True\n",
    "            ) \n",
    "            \n",
    "            output, _ = model_eval(model, spec, device)\n",
    "\n",
    "            window = vorbis_window(N_FFTS).to(device)\n",
    "            output = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                                   window=window,\n",
    "                                   # onesided=True,\n",
    "                                   return_complex=False,\n",
    "                                   normalized=True,\n",
    "                                   center=True)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            result_rtf_full.append((signal.shape[-1] / SR) / (end_time - start_time))\n",
    "            nisqa_score, _, _ = process(output.detach().cpu(), SR, nisqa, h0_nisqa, c0_nisqa, nisqa_args)\n",
    "            result_nisqa_full.append(nisqa_score)\n",
    "\n",
    "            for j in range(0, signal.shape[-1], window_size):\n",
    "                chunk = signal[..., j:j+window_size]\n",
    "                \n",
    "                if chunk.shape[-1] < 10_000:\n",
    "                    continue\n",
    "\n",
    "                start_time = time.time()\n",
    "                spec = torch.stft(\n",
    "                    chunk,\n",
    "                    n_fft=N_FFTS,\n",
    "                    hop_length=HOP_LENGTH,\n",
    "                    # onesided=True,\n",
    "                    win_length=N_FFTS,\n",
    "                    window=window,\n",
    "                    return_complex=True,\n",
    "                    normalized=True,\n",
    "                    center=True\n",
    "                )\n",
    "\n",
    "                output, _ = model_eval(model, spec, device)\n",
    "\n",
    "                window = vorbis_window(N_FFTS).to(device)\n",
    "                output = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                                    window=window,\n",
    "                                    # onesided=True,\n",
    "                                    return_complex=False,\n",
    "                                    normalized=True,\n",
    "                                    center=True)\n",
    "                \n",
    "                end_time = time.time()\n",
    "\n",
    "\n",
    "                result_rtf_chunk.append((chunk.shape[-1] / SR) / (end_time - start_time))\n",
    "                # print(output.shape)\n",
    "                nisqa_score, _, _ = process(output.detach().cpu(), SR, nisqa, h0_nisqa, c0_nisqa, nisqa_args)\n",
    "\n",
    "                result_nisqa_chunk.append(nisqa_score)\n",
    "                \n",
    "\n",
    "    print(f\"Mean nisqa for full audio: \", torch.stack(result_nisqa_full).mean(dim=0))\n",
    "    print(f\"Mean rtf for full audio: \", torch.tensor(result_rtf_full).mean(dim=0), 1 / torch.tensor(result_rtf_full).mean(dim=0))\n",
    "    print(\"---\" * 10)\n",
    "    print(\"Mean nisqa for \\\"stream\\\" audio: \", torch.stack(result_nisqa_chunk).mean(dim=0))\n",
    "    print(\"Mean rtf for \\\"stream\\\" audio: \", torch.tensor(result_rtf_chunk).mean(dim=-1), 1 / torch.tensor(result_rtf_chunk).mean(dim=-1))\n",
    "\n",
    "    return result_nisqa_full, result_rtf_full, result_nisqa_chunk, result_rtf_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "557c22ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [10:24<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean nisqa for full audio:  tensor([[3.152, 3.883, 3.319, 3.291, 3.419]])\n",
      "Mean rtf for full audio:  tensor(10.644) tensor(0.094)\n",
      "------------------------------\n",
      "Mean nisqa for \"stream\" audio:  tensor([[2.667, 3.705, 3.253, 2.981, 2.879]])\n",
      "Mean rtf for \"stream\" audio:  tensor(7.771) tensor(0.129)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "_ = check_stream_inference(fspen, test_dataloader, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2bbf6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.audio.pesq import PerceptualEvaluationSpeechQuality\n",
    "from torch_stoi import NegSTOILoss\n",
    "\n",
    "srmr = SpeechReverberationModulationEnergyRatio(fs=48_000, norm=True)\n",
    "pesq = PerceptualEvaluationSpeechQuality(fs=16_000, mode=\"wb\").to(\"cuda\")\n",
    "stoi = NegSTOILoss(SR, use_vad=False, do_resample=False).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f174efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.transforms import Resample\n",
    "\n",
    "\n",
    "def get_metrics(model, loader, device=\"cpu\"):\n",
    "    model.eval()\n",
    "    \n",
    "    model = model.to(device)\n",
    "    \n",
    "    nisqa_scores = []\n",
    "    pesq_scores = []\n",
    "    stoi_scores = []\n",
    "    srmr_scores = []\n",
    "    with torch.no_grad():\n",
    "        for signal, target in tqdm(loader):\n",
    "            signal = signal.to(device)\n",
    "            target = target.to(device)\n",
    "            window = vorbis_window(N_FFTS).to(device)\n",
    "    \n",
    "            spec = torch.stft(\n",
    "                signal,\n",
    "                n_fft=N_FFTS,\n",
    "                hop_length=HOP_LENGTH,\n",
    "                # onesided=True,\n",
    "                win_length=N_FFTS,\n",
    "                window=window,\n",
    "                return_complex=True,\n",
    "                normalized=True,\n",
    "                center=True\n",
    "            ) \n",
    "            \n",
    "            output, _ = model_eval(model, spec, device)\n",
    "\n",
    "            window = vorbis_window(N_FFTS).to(device)\n",
    "            output = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                                   window=window,\n",
    "                                   # onesided=True,\n",
    "                                   return_complex=False,\n",
    "                                   normalized=True,\n",
    "                                   center=True)\n",
    "            \n",
    "            min_l = min(output.shape[-1], signal.shape[-1])\n",
    "            nisqa_score, _, _ = process(output.detach().cpu(), SR, nisqa, h0_nisqa, c0_nisqa, nisqa_args)\n",
    "            stoi_score = stoi(output[..., :min_l], target[..., :min_l])\n",
    "            srmr_score = srmr(output.detach().cpu())\n",
    "            \n",
    "            resampler = Resample(SR, 16_000)\n",
    "            output = resampler(output.cpu()).cuda()\n",
    "            target = resampler(target.cpu()).cuda()\n",
    "            min_l = min(output.shape[-1], target.shape[-1])\n",
    "\n",
    "            try:\n",
    "                pesq_score = pesq(output[..., :min_l], target[..., :min_l])\n",
    "            except Exception as e:\n",
    "                # print(min_l)\n",
    "                # out_wave_ = output.reshape(-1)\n",
    "                # target_ = target.reshape(-1)\n",
    "                # write('exception_out.wav', SR, out_wave_.cpu().detach().numpy())\n",
    "                # write('exception_in.wav', SR, target_.cpu().detach().numpy())\n",
    "                continue\n",
    "\n",
    "            nisqa_scores.append(nisqa_score[0])\n",
    "            srmr_scores.append(srmr_score)\n",
    "            stoi_scores.append(stoi_score.cpu())\n",
    "            pesq_scores.append(pesq_score.cpu())\n",
    "\n",
    "    result = {\"nisqa\": nisqa_scores, \"stoi\": stoi_scores, \"srmr\": srmr_scores, \"pesq\": pesq_scores}\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c28e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [11:00<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics = get_metrics(fspen, test_dataloader, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88021dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NISQA: tensor([3.117, 3.867, 3.311, 3.282, 3.380])\n",
      "PESQ: tensor([1.772])\n",
      "SRMR: tensor([1.879])\n",
      "STOI: tensor([0.837])\n"
     ]
    }
   ],
   "source": [
    "print(\"NISQA:\", torch.vstack(metrics[\"nisqa\"]).mean(dim=0))\n",
    "print(\"PESQ:\", torch.vstack(metrics[\"pesq\"]).mean(dim=0))\n",
    "print(\"SRMR:\", torch.vstack(metrics[\"srmr\"]).mean(dim=0))\n",
    "print(\"STOI:\", -torch.vstack(metrics[\"stoi\"]).mean(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba915f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sig, gt, gt_noise, gt_rir = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "391695b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv1d'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
      "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
      "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
      "[INFO] Register count_gru() for <class 'torch.nn.modules.rnn.GRU'>.\n",
      "[INFO] Register count_normalization() for <class 'torch.nn.modules.normalization.LayerNorm'>.\n",
      "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.ConvTranspose1d'>.\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "\n",
    "window = vorbis_window(N_FFTS)\n",
    "\n",
    "input_spec = torch.stft(\n",
    "            input_sig[..., :SR],\n",
    "            n_fft=N_FFTS,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            # onesided=True,\n",
    "            win_length=N_FFTS,\n",
    "            window=window,\n",
    "            return_complex=True,\n",
    "            normalized=True,\n",
    "            center=True\n",
    "        )\n",
    "\n",
    "input_spec = input_spec.to(\"cpu\")\n",
    "\n",
    "abs_spectrum = input_spec.abs()\n",
    "input_spec_ = torch.permute(torch.view_as_real(input_spec), dims=(0, 2, 3, 1))\n",
    "batch, frames, channels, frequency = input_spec_.shape\n",
    "abs_spectrum = torch.permute(abs_spectrum, dims=(0, 2, 1))\n",
    "abs_spectrum = torch.reshape(abs_spectrum, shape=(batch, frames, 1, frequency))\n",
    "h0 = [[torch.zeros(1, batch * 64, 16 // 8, device=input_spec.device) for _ in range(8)] for _ in range(3)]\n",
    "\n",
    "# output, hid_out = fspen(input_spec_, abs_spectrum, h0)\n",
    "\n",
    "flops, params = profile(fspen.cpu(), inputs=(input_spec_, abs_spectrum, h0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88f34c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flops:  252744192.0\n",
      "Params:  49600.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Flops: \", flops)\n",
    "print(\"Params: \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba74559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fspen = FullSubPathExtension(configs=configs)\n",
    "fspen.load_state_dict(state_d[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c95b0090",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sig, gt, gt_noise, gt_rir = dataset[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b212403",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = vorbis_window(N_FFTS)\n",
    "\n",
    "spec = torch.stft(\n",
    "            input_sig,\n",
    "            n_fft=N_FFTS,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            # onesided=True,\n",
    "            win_length=N_FFTS,\n",
    "            window=window,\n",
    "            return_complex=True,\n",
    "            normalized=True,\n",
    "            center=True\n",
    "        )\n",
    "\n",
    "output, _ = model_eval(fspen, spec, DEVICE)\n",
    "\n",
    "window = vorbis_window(N_FFTS)\n",
    "# print(output_d.shape, input_spec.shape)\n",
    "out_wave = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                       window=window,\n",
    "                       # onesided=True,\n",
    "                       return_complex=False,\n",
    "                       normalized=True,\n",
    "                       center=True)\n",
    "\n",
    "out_wave = out_wave.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df4ec595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "\n",
    "write('input_sig_full.wav', SR, input_sig.cpu().detach().numpy()[0])\n",
    "write('gt_full.wav', SR, gt.cpu().detach().numpy()[0])\n",
    "write('output_full.wav', SR, out_wave.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b978048d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ems_dereverb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
