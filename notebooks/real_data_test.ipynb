{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.304607Z",
     "start_time": "2025-09-02T11:19:48.644625Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyroomacoustics as pra\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import profiler\n",
    "import torchaudio\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from src.dataset import SignalDataset, TRUNetDataset\n",
    "from src.loss import loss_tot, loss_MR, loss_MR_w\n",
    "from models.fspen import FullSubPathExtension \n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77d1bf7132dff78c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.308277Z",
     "start_time": "2025-09-02T11:19:51.305940Z"
    }
   },
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(\"..\", \"data\", \"musan\", \"speech\")\n",
    "# TRAIN_DIR = os.path.join(DATA_DIR, \"train_chunks\")\n",
    "# TEST_DIR = os.path.join(DATA_DIR, \"test_chunks\")\n",
    "\n",
    "DATA_DIR = os.path.join(\"data\", \"real\")\n",
    "\n",
    "CHKP_DIR = os.path.join(\"checkpoints\")\n",
    "np.set_printoptions(precision=3)\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d14d195849dcabc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.319938Z",
     "start_time": "2025-09-02T11:19:51.308947Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's cpu time!!!\n"
     ]
    }
   ],
   "source": [
    "N_FFTS = 512\n",
    "HOP_LENGTH = 256\n",
    "SR = 48_000\n",
    "\n",
    "DEVICE = \"cpu\" # torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"It's {DEVICE} time!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573280716462d1d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.331537Z",
     "start_time": "2025-09-02T11:19:51.321551Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TRUNetDataset(DATA_DIR, sr=48_000, return_noise=False, return_rir=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f9d8bdaa4250d27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.610811Z",
     "start_time": "2025-09-02T11:19:51.332960Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 2\n"
     ]
    }
   ],
   "source": [
    "from src.fspen_configs import TrainConfig, TrainConfigLarge, TrainConfigRNN, TrainConfigRNN1, TrainConfigRNN2\n",
    "\n",
    "configs = TrainConfigLarge()\n",
    "print(sum(configs.bands_num_in_groups), configs.dual_path_extension[\"num_modules\"])\n",
    "fspen = FullSubPathExtension(configs=configs)# .to(DEVICE)\n",
    "\n",
    "state_d = torch.load(os.path.join(CHKP_DIR, \"fspen_chkp\", \"fspen_voicebank_subband_loss_causal#2.pt\"), weights_only=False)\n",
    "\n",
    "# model = FullSubPathExtension(nfft=512, hop=256)\n",
    "# fspen.load_state_dict(state_d[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b09101a88b55bb53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.621219Z",
     "start_time": "2025-09-02T11:19:51.611828Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fspen.load_state_dict(state_d[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f512abd99d7917d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.626410Z",
     "start_time": "2025-09-02T11:19:51.622340Z"
    }
   },
   "outputs": [],
   "source": [
    "def vorbis_window(winlen, device=\"cuda\"):\n",
    "    sq = torch.sin(torch.pi/2*(torch.sin(torch.pi/winlen*(torch.arange(winlen)-0.5))**2)).float()\n",
    "    return sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfb30d6ea498f656",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.638818Z",
     "start_time": "2025-09-02T11:19:51.627467Z"
    }
   },
   "outputs": [],
   "source": [
    "file_paths = os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56021fa2cf4bd7b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:19:51.650080Z",
     "start_time": "2025-09-02T11:19:51.640280Z"
    }
   },
   "outputs": [],
   "source": [
    "PCS = torch.ones(257, device=DEVICE)      # Perceptual Contrast Stretching\n",
    "PCS[0:3] = 1\n",
    "PCS[3:6] = 1.070175439\n",
    "PCS[6:9] = 1.182456140\n",
    "PCS[9:12] = 1.287719298\n",
    "PCS[12:138] = 1.4       # Pre Set\n",
    "PCS[138:166] = 1.322807018\n",
    "PCS[166:200] = 1.238596491\n",
    "PCS[200:241] = 1.161403509\n",
    "PCS[241:256] = 1.077192982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7048fce4006a427a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:20:37.522229Z",
     "start_time": "2025-09-02T11:19:51.651995Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:06<00:00, 11.08s/it]\n"
     ]
    }
   ],
   "source": [
    "window = vorbis_window(512)\n",
    "\n",
    "for x in tqdm(file_paths):\n",
    "    # input_sig, gt, gt_noise, gt_rir = dataset[i]\n",
    "    signal, signal_sr = torchaudio.load(os.path.join(DATA_DIR, x))\n",
    "    \n",
    "    # signal = signal / torch.max(torch.abs(signal))\n",
    "    \n",
    "    spec = torch.stft(\n",
    "            signal,\n",
    "            n_fft=N_FFTS,\n",
    "            hop_length=HOP_LENGTH,\n",
    "            # onesided=True,\n",
    "            win_length=512,\n",
    "            window=window,\n",
    "            return_complex=True,\n",
    "            normalized=True,\n",
    "            center=True\n",
    "        ) \n",
    "    \n",
    "    input_spec_pcs = PCS[:, None, None] * torch.transpose(torch.log1p(torch.abs(spec)), 1, 0)\n",
    "    input_spec_pcs = torch.transpose(input_spec_pcs, 1, 0)\n",
    "    input_spec_pcs = torch.polar(input_spec_pcs, spec.angle())\n",
    "    abs_spectrum_pcs = input_spec_pcs.abs()\n",
    "    # print(torch.transpose(torch.log1p(torch.abs(input_spec)), 1, 0).dtype)\n",
    "    input_spec_pcs = torch.permute(torch.view_as_real(input_spec_pcs), dims=(0, 2, 3, 1))\n",
    "    batch, frames, channels, frequency = input_spec_pcs.shape\n",
    "\n",
    "    abs_spectrum_pcs = torch.permute(abs_spectrum_pcs, dims=(0, 2, 1))\n",
    "    abs_spectrum_pcs = torch.reshape(abs_spectrum_pcs, shape=(batch, frames, 1, frequency))\n",
    "    \n",
    "    output, _ = fspen(input_spec_pcs, abs_spectrum_pcs)\n",
    "    \n",
    "    output = torch.permute(output, dims=(0, 3, 1, 2))\n",
    "    output[..., 0] = torch.expm1(output[..., 0])\n",
    "    output = torch.view_as_complex(output)\n",
    "    \n",
    "    window = vorbis_window(N_FFTS)# .to(device)\n",
    "    # print(output_d.shape, input_spec.shape)\n",
    "    out_wave = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                           window=window,\n",
    "                           # onesided=True,\n",
    "                           return_complex=False,\n",
    "                           normalized=True,\n",
    "                           center=True)\n",
    "    out_wave = out_wave.reshape(-1)\n",
    "    write(f'notebooks/real_test/{x}', SR, out_wave.cpu().detach().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cb874738d7703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T11:20:37.555412Z",
     "start_time": "2025-09-02T11:20:37.538764Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ems_dereverb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
