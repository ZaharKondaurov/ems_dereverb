{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1011a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyroomacoustics as pra\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import profiler\n",
    "import torchaudio\n",
    "from torchmetrics.audio import SpeechReverberationModulationEnergyRatio, ShortTimeObjectiveIntelligibility\n",
    "\n",
    "\n",
    "from einops import rearrange\n",
    "\n",
    "from src.dataset import SignalDataset, TRUNetDataset\n",
    "from src.loss import loss_tot, loss_MR, loss_MR_w\n",
    "from models.fspen import FullSubPathExtension \n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554e0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.path.join(\"..\", \"data\", \"musan\", \"speech\")\n",
    "# TRAIN_DIR = os.path.join(DATA_DIR, \"train_chunks\")\n",
    "# TEST_DIR = os.path.join(DATA_DIR, \"test_chunks\")\n",
    "\n",
    "DATA_DIR = os.path.join(\"data\", \"wav48\")\n",
    "TRAIN_DIR = os.path.join(DATA_DIR, \"clean_trainset_56spk_wav\")\n",
    "\n",
    "TEST_DIR = os.path.join(DATA_DIR, \"clean_testset_wav\")\n",
    "# TRAIN_DIR = os.path.join(DATA_DIR, \"data_thchs30\", \"train_1\")\n",
    "# TEST_DIR = os.path.join(DATA_DIR, \"data_thchs30\", \"train_1\")\n",
    "# RIR_DIR = os.path.join(\"..\", \"data\", \"rirs_noises\", \"RIRS_NOISES\", \"real_rirs\")\n",
    "# RIR_DIR = os.path.join(\"..\", \"data\", \"RIRs\", )\n",
    "RIR_DIR = os.path.join(\"data\", \"rirs48\", )\n",
    "# NOISE_DIR = os.path.join(\"..\", \"data\", \"rirs_noises\", \"RIRS_NOISES\", \"real_rirs_isotropic_noises\")\n",
    "NOISE_DIR = os.path.join(\"data\", \"TAU-urban-acoustic\")\n",
    "CHKP_DIR = \"checkpoints\"\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "torch.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5490485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's cuda time!!!\n"
     ]
    }
   ],
   "source": [
    "N_FFTS = 512\n",
    "HOP_LENGTH = 256\n",
    "SR = 48_000\n",
    "\n",
    "DEVICE = \"cuda\" # torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"It's {DEVICE} time!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "426ab26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zakhar/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "from NISQA_s.src.core.model_torch import model_init\n",
    "from NISQA_s.src.utils.process_utils import process\n",
    "\n",
    "NISQA_PATH = \"NISQA_s/config/nisqa_s.yaml\"\n",
    "\n",
    "with open(NISQA_PATH, 'r') as stream:\n",
    "    nisqa_args = yaml.safe_load(stream)\n",
    "nisqa_args[\"ms_n_fft\"] = N_FFTS\n",
    "nisqa_args[\"hop_length\"] = HOP_LENGTH\n",
    "nisqa_args[\"ms_win_length\"] = N_FFTS\n",
    "nisqa_args[\"ckp\"] = nisqa_args[\"ckp\"][3:]\n",
    "\n",
    "nisqa, h0_nisqa, c0_nisqa = model_init(nisqa_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "106504ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TRUNetDataset(DATA_DIR, sr=48_000, noise_dir=NOISE_DIR, rir_dir=RIR_DIR, snr=[5, 10], rir_proba=0.7, noise_proba=0.7, return_noise=False, return_rir=False, max_seq_len=48_000 * 5)\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [0.95, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bbf385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 2\n"
     ]
    }
   ],
   "source": [
    "from src.fspen_configs import TrainConfig, TrainConfigLarge, TrainConfigLarge1, TrainConfigRNN1, TrainConfigRNN2\n",
    "\n",
    "configs = TrainConfigLarge()\n",
    "print(sum(configs.bands_num_in_groups), configs.dual_path_extension[\"num_modules\"])\n",
    "fspen = FullSubPathExtension(configs=configs).to(DEVICE)\n",
    "\n",
    "state_d = torch.load(os.path.join(CHKP_DIR, \"fspen_chkp\", \"fspen_voicebank_subband_loss#2.pt\"), weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "228a369b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fspen.load_state_dict(state_d[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "872a8eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vorbis_window(winlen, device=\"cuda\"):\n",
    "    sq = torch.sin(torch.pi/2*(torch.sin(torch.pi/winlen*(torch.arange(winlen)-0.5))**2)).float()\n",
    "    return sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e39e311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCS = torch.ones(257, device=DEVICE)      # Perceptual Contrast Stretching\n",
    "PCS[0:3] = 1\n",
    "PCS[3:6] = 1.070175439\n",
    "PCS[6:9] = 1.182456140\n",
    "PCS[9:12] = 1.287719298\n",
    "PCS[12:138] = 1.4       # Pre Set\n",
    "PCS[138:166] = 1.322807018\n",
    "PCS[166:200] = 1.238596491\n",
    "PCS[200:241] = 1.161403509\n",
    "PCS[241:256] = 1.077192982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495f86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import write\n",
    "\n",
    "def eval(model, input_sig, gt=None, hidden_state=None):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    window = vorbis_window(512).to(DEVICE)\n",
    "    spec = torch.stft(\n",
    "        input_sig,\n",
    "        n_fft=N_FFTS,\n",
    "        hop_length=HOP_LENGTH,\n",
    "        # onesided=True,\n",
    "        win_length=512,\n",
    "        window=window,\n",
    "        return_complex=True,\n",
    "        normalized=True,\n",
    "        center=False\n",
    "    ) \n",
    "\n",
    "    # input_spec_ = spec\n",
    "    spec_pcs = PCS[:, None, None] * torch.transpose(torch.log1p(torch.abs(spec)), 1, 0)\n",
    "    spec_pcs = torch.transpose(spec_pcs, 1, 0)\n",
    "    spec_pcs = torch.polar(spec_pcs, spec.angle())\n",
    "    input_spec = torch.permute(torch.view_as_real(spec_pcs), dims=(0, 2, 3, 1))\n",
    "    abs_spectrum = spec_pcs.abs()\n",
    "    batch, frames, channels, frequency = input_spec.shape\n",
    "\n",
    "    abs_spectrum = torch.permute(abs_spectrum, dims=(0, 2, 1))\n",
    "    abs_spectrum = torch.reshape(abs_spectrum, shape=(batch, frames, 1, frequency))\n",
    "    # h0 = [[torch.randn(1, batch * 32, 16 // 8,  ) for _ in range(8)]\n",
    "    #                for _ in range(3)]\n",
    "\n",
    "    if hidden_state is None:\n",
    "        hidden_state = [[torch.zeros(1, batch * 32, 16 // 8, device=input_spec.device) for _ in range(8)] for _ in range(2)]\n",
    "\n",
    "    output, new_hidden_state = model(input_spec, abs_spectrum, hidden_state)\n",
    "\n",
    "    output = torch.permute(output, dims=(0, 3, 1, 2))\n",
    "    output = torch.view_as_complex(output)\n",
    "\n",
    "    window = vorbis_window(N_FFTS).to(DEVICE)\n",
    "    # print(output_d.shape, input_spec.shape)\n",
    "    out_wave = torch.istft(output, n_fft=N_FFTS, hop_length=HOP_LENGTH, win_length=N_FFTS,\n",
    "                        window=window,\n",
    "                        # onesided=True,\n",
    "                        return_complex=False,\n",
    "                        normalized=True,\n",
    "                        center=False)\n",
    "    end_time = time.time()\n",
    "    # print(out_wave.shape, input_sig.shape)\n",
    "    # print(input_spec.shape, output.shape)\n",
    "    # out_wave = out_wave / torch.max(torch.abs(out_wave))\n",
    "    nisqa_score, _, _ = process(out_wave.detach().cpu(), 48_000, nisqa, h0_nisqa, c0_nisqa, nisqa_args)\n",
    "    # print(out_wave.shape)\n",
    "    # out_wave_1 = out_wave.reshape(-1)\n",
    "    # gt_1 = gt.reshape(-1)\n",
    "    # input_sig_1 = input_sig.reshape(-1)\n",
    "    # write('input_stream.wav', SR, input_sig_1.cpu().detach().numpy())\n",
    "    # write('output_full_stream.wav', SR, out_wave_1.cpu().detach().numpy())\n",
    "    # write('gt_stream.wav', SR, gt_1.cpu().detach().numpy())\n",
    "    return nisqa_score, (input_sig.shape[-1] / SR) / (end_time - start_time), new_hidden_state\n",
    "\n",
    "\n",
    "def check_stream_inference(model, dataset, window_size = 1 * SR):\n",
    "    model.eval()\n",
    "    result_nisqa_full = []\n",
    "    result_rtf_full = []\n",
    "    result_nisqa_chunk = []\n",
    "    result_rtf_chunk = [] \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            input_sig, gt, _, _ = dataset[i]\n",
    "            input_sig = input_sig.to(DEVICE)\n",
    "            nisqa_score_full, rtf_full, _ = eval(model, input_sig, gt)\n",
    "            # print(nisqa_score_full)\n",
    "            result_nisqa_full.append(nisqa_score_full)\n",
    "            result_rtf_full.append(rtf_full)\n",
    "            # print(nisqa_score_full)\n",
    "            hidden_state = [[torch.zeros(1, 1 * 32, 16 // 8, device=input_sig.device) for _ in range(8)] for _ in range(2)]\n",
    "            nisqa_score_chunk_mean = []\n",
    "            rtf_chunk_mean = []\n",
    "            for j in range(0, input_sig.shape[-1], window_size):\n",
    "                chunk = input_sig[..., j:j+window_size]\n",
    "                \n",
    "                nisqa_score_chunk, rtf_chunk, hidden_state = eval(model, chunk, hidden_state=hidden_state)\n",
    "                nisqa_score_chunk_mean.append(nisqa_score_chunk)\n",
    "                rtf_chunk_mean.append(rtf_chunk)\n",
    "\n",
    "            # print(torch.stack(nisqa_score_chunk_mean).mean(dim=0).shape)\n",
    "            result_nisqa_chunk.append(torch.stack(nisqa_score_chunk_mean).mean(dim=0))\n",
    "            result_rtf_chunk.append(torch.tensor(rtf_chunk_mean).mean())\n",
    "\n",
    "    print(f\"Mean nisqa for full audio: \", torch.stack(result_nisqa_full).mean(dim=0))\n",
    "    print(f\"Mean rtf for full audio: \", torch.tensor(result_rtf_full).mean(dim=0))\n",
    "    print(\"---\" * 10)\n",
    "    print(\"Mean nisqa for \\\"stream\\\" audio: \", torch.stack(result_nisqa_chunk).mean(dim=0))\n",
    "    print(\"Mean rtf for \\\"stream\\\" audio: \", torch.tensor(result_rtf_chunk).mean(dim=-1))\n",
    "\n",
    "    return result_nisqa_full, result_rtf_full, result_nisqa_chunk, result_rtf_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a377f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/44242 [00:03<2:43:48,  4.50it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcheck_stream_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfspen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 73\u001b[0m, in \u001b[0;36mcheck_stream_inference\u001b[0;34m(model, dataset, window_size)\u001b[0m\n\u001b[1;32m     71\u001b[0m input_sig, gt, _, _ \u001b[38;5;241m=\u001b[39m dataset[i]\n\u001b[1;32m     72\u001b[0m input_sig \u001b[38;5;241m=\u001b[39m input_sig\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 73\u001b[0m nisqa_score_full, rtf_full, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# print(nisqa_score_full)\u001b[39;00m\n\u001b[1;32m     75\u001b[0m result_nisqa_full\u001b[38;5;241m.\u001b[39mappend(nisqa_score_full)\n",
      "Cell \u001b[0;32mIn[10], line 52\u001b[0m, in \u001b[0;36meval\u001b[0;34m(model, input_sig, gt, hidden_state)\u001b[0m\n\u001b[1;32m     48\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# print(out_wave.shape, input_sig.shape)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# print(input_spec.shape, output.shape)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# out_wave = out_wave / torch.max(torch.abs(out_wave))\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m nisqa_score, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_wave\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m48_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnisqa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0_nisqa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0_nisqa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnisqa_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# print(out_wave.shape)\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# out_wave_1 = out_wave.reshape(-1)\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# gt_1 = gt.reshape(-1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# write('output_full_stream.wav', SR, out_wave_1.cpu().detach().numpy())\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# write('gt_stream.wav', SR, gt_1.cpu().detach().numpy())\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m nisqa_score, (input_sig\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m SR) \u001b[38;5;241m/\u001b[39m (end_time \u001b[38;5;241m-\u001b[39m start_time), new_hidden_state\n",
      "File \u001b[0;32m~/ems_dereverb/NISQA_s/src/utils/process_utils.py:105\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(audio, sr, model, h0, c0, args)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;66;03m# print(out[0].numpy())\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 105\u001b[0m         out, h0, c0 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_wins\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# print(out[0].numpy())\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out, h0, c0\n",
      "File \u001b[0;32m~/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ems_dereverb/NISQA_s/src/core/model_torch.py:225\u001b[0m, in \u001b[0;36mNISQA_DIM.forward\u001b[0;34m(self, x, n_wins, h0, c0)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, n_wins, h0, c0):\n\u001b[1;32m    224\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcnn(x, n_wins)\n\u001b[0;32m--> 225\u001b[0m     x, h, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_wins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m     out \u001b[38;5;241m=\u001b[39m [mod(x, n_wins) \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool_layers]\n\u001b[1;32m    227\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/ems_dereverb/NISQA_s/src/core/model_torch.py:162\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, x, n_wins, h0, c0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm\u001b[38;5;241m.\u001b[39mflatten_parameters()\n\u001b[1;32m    161\u001b[0m x, (h, c) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlstm(x, (h0, c0))\n\u001b[0;32m--> 162\u001b[0m x, _ \u001b[38;5;241m=\u001b[39m \u001b[43mpad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_wins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x, h, c\n",
      "File \u001b[0;32m~/miniconda3/envs/ems_dereverb/lib/python3.10/site-packages/torch/nn/utils/rnn.py:333\u001b[0m, in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected total_length to be at least the length \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    329\u001b[0m                          \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof the longest sequence in input, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m                          \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotal_length=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and max sequence length being \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_seq_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    331\u001b[0m                          )\n\u001b[1;32m    332\u001b[0m     max_seq_length \u001b[38;5;241m=\u001b[39m total_length\n\u001b[0;32m--> 333\u001b[0m padded_output, lengths \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pad_packed_sequence\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msequence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m unsorted_indices \u001b[38;5;241m=\u001b[39m sequence\u001b[38;5;241m.\u001b[39munsorted_indices\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsorted_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "check_stream_inference(fspen, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "846ef0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "960"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SR // 1000 * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12305cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = check_stream_inference(fspen, dataset, window_size=SR // 1000 * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e123feb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ems_dereverb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
